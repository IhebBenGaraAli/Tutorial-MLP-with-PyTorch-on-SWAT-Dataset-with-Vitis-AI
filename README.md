# Tutoriel : D√©ploiement d'un Mod√®le MLP sur DPU avec PyTorch et Vitis AI

Ce tutoriel explique comment d√©ployer un mod√®le de classification binaire (normal ou attaque) bas√© sur un MLP, entra√Æn√© avec PyTorch et optimis√© pour l'inf√©rence sur un DPU avec Vitis AI. Nous couvrons les √©tapes de quantification, compilation et √©valuation des performances √©nerg√©tiques sur la carte Zynq Ultra96.

## 1. Pr√©requis

- **Syst√®me Linux**
- **Docker install√© et configur√©**
- **Acc√®s √† Vitis AI 3.5**
- **Carte Zynq Ultra96 pour l'inf√©rence sur DPU**

## 2. Installation de Vitis AI

Cloner le d√©p√¥t de Vitis AI avec :
```sh
git clone https://github.com/Xilinx/Vitis-AI
```

Depuis le r√©pertoire Vitis AI 3.5, ex√©cutez :
```sh
cd ${WRK_DIR}
cd docker
./docker_build.sh -t gpu -f pytorch
```
V√©rifiez l'installation avec :
```sh
docker images
```

## 3. Lancer le conteneur Docker

Ex√©cutez les commandes suivantes :
```sh
cd ${WRK_DIR}  # R√©pertoire de travail Vitis AI
./docker_run.sh xilinx/vitis-ai-pytorch-gpu:latest
conda activate vitis-ai-pytorch
cd /workspace/tutorials/Tutorial-MLP-with-PyTorch-on-SWAT-Dataset-with-Vitis-AI
```
Ajoutez les paquets n√©cessaires :
```sh
pip install randaugment torchsummary
```

## 4. Jeu de donn√©es SWaT

Le jeu de donn√©es SWaT est disponible ici :
[SWaT Dataset](https://itrust.sutd.edu.sg/itrust-labs_datasets/dataset_info/)

Caract√©ristiques du fichier **SWaT_Dataset_Attack_v0.csv** :
- 11 jours d'op√©ration (7 jours normaux, 4 jours avec attaques)
- Captures du trafic r√©seau et des 51 capteurs/actionneurs
- 41 attaques simul√©es et labellis√©es

Le fichier **SWaT_Dataset_Attack_v0.csv** doit √™tre plac√© dans :
```
build/data/swat_dataset
```

## 5. Entra√Ænement du mod√®le MLP

Dans le r√©pertoire **train_mlp**, ex√©cutez le script d'entra√Ænement :
```sh
python train_mlp_pytorch.py
```
Ce script g√©n√®re un mod√®le avec une pr√©cision de 98 %, sauvegard√© sous forme de fichier `.pt`.

Les poids doivent √™tre stock√©s dans :
```
build/float
```

## 6. Quantification du mod√®le

Ex√©cutez la quantification avec :
```sh
/workspace/vitis_ai_mlp$ ./scripts/quant.sh
```

## 7. Compilation pour le DPU cible

V√©rifiez que le fichier **arch.json** correspond √† votre DPU, puis compilez :
```sh
./comp.sh
```

## 8. Inf√©rence sur la carte Ultra96

Une fois la quantification et la compilation termin√©es :
- Copiez le mod√®le **.xmodel** dans `inference_dpu_mlp`
- Copiez tout le dossier sur la carte Ultra96
- Ex√©cutez l'inf√©rence sur le DPU

## 9. Mesure de la consommation √©nerg√©tique

Dans le dossier **inference_dpu_mlp**, utilisez le script **measure_power** pour mesurer la consommation d'√©nergie pendant l'inf√©rence.

## 10. Conclusion

Ce tutoriel vous permet de d√©ployer un mod√®le MLP optimis√© pour l'inf√©rence sur DPU, en passant par l'entra√Ænement, la quantification et la compilation. Vous pouvez ainsi mesurer les performances et la consommation √©nerg√©tique du mod√®le sur la carte Ultra96.

üöÄ Bon d√©ploiement !

